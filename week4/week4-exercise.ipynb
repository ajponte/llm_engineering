{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Week 4 Exercise\n",
    "\n",
    "## Goal\n",
    "Create a script to translate Hirigana (ひりがな）to Katakana (カタカナ）to Kanji (漢字) using a specific LLM model (closed or open source).\n"
   ],
   "id": "68becebcfc07920b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T08:21:37.187891Z",
     "start_time": "2025-07-10T08:21:37.177616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ],
   "id": "35a764d6b53810bd",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Application-level configurations**",
   "id": "cc054274dccea5a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T08:10:21.807139Z",
     "start_time": "2025-07-10T08:10:21.790086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DEFAULT_OPENAI_MODEL = \"gpt-4o\"\n",
    "DEFAULT_CLAUDE_MODEL = \"claude-3-5-sonnet-20240620\"\n",
    "# Toggle gradio auto-launching the UI.\n",
    "DEFAULT_GRADIO_UI_AUTO_LAUNCH = True\n",
    "\n",
    "_CONFIG = {\n",
    "    'OPENAI_MODEL': DEFAULT_OPENAI_MODEL,\n",
    "    'CLAUDE_MODEL': DEFAULT_CLAUDE_MODEL,\n",
    "    'GRADIO_UI_AUTO_LAUNCH': DEFAULT_GRADIO_UI_AUTO_LAUNCH\n",
    "}\n"
   ],
   "id": "90aa682c3d98a91a",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Load API Keys**",
   "id": "626d0d8381baec0c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T08:10:24.847311Z",
     "start_time": "2025-07-10T08:10:24.837737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from translate.error import EnvironmentException\n",
    "\n",
    "\n",
    "# Load API Keys.\n",
    "try:\n",
    "    load_dotenv(override=True)\n",
    "    os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "    os.environ['ANTHROPIC_API_KEY'] = os.getenv('ANTHROPIC_API_KEY', 'your-key-if-not-using-env')\n",
    "    os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN', 'your-key-if-not-using-env')\n",
    "except Exception as e:\n",
    "    error_message = \"Failure to setup environment variables, please check your configuration.\"\n",
    "    print(error_message)\n",
    "    raise EnvironmentException(message=error_message, cause=e)\n",
    "print(\"API Keys loaded!\")"
   ],
   "id": "21dba0501cb7cd6e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Keys loaded!\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Defining System Prompt**",
   "id": "975a0ff59ca1daaa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T08:10:26.013755Z",
     "start_time": "2025-07-10T08:10:26.010015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "_SYSTEM_PROMPT = \"You are an assistant that translates Japanese hirigana (ひりがな) to its closest kanji (漢字). \"\n",
    "_SYSTEM_PROMPT = \"The input hirigana might be in romaji or actual hirigana characters. \"\n",
    "_SYSTEM_PROMPT += \"If you find multiple matches for the input hirigana, use your best reasoning skills to match the entire word or phrase. \"\n",
    "_SYSTEM_PROMPT += \"If you're unable to find any match for the input hirigana, let the user know.\""
   ],
   "id": "9f5be36d66c9f2ad",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**User Prompt**",
   "id": "891a96d3e5bf53ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T08:10:27.629655Z",
     "start_time": "2025-07-10T08:10:27.625084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def user_prompt_for(hirigana: str) -> str:\n",
    "    \"\"\"\n",
    "    Return the user prompt for a given hirigana input.\n",
    "\n",
    "    param: hirigana: The input hirigana to translate to Kanji.\n",
    "    \"\"\"\n",
    "    if not hirigana:\n",
    "        raise ValueError(\"hirigana value is required!\")\n",
    "    _user_prompt = f\"Translate the following hirigana to kanji: {hirigana}\"\n",
    "    return _user_prompt\n"
   ],
   "id": "86303615394e7d15",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T08:11:41.473960Z",
     "start_time": "2025-07-10T08:11:40.748048Z"
    }
   },
   "cell_type": "markdown",
   "source": "## Translation Model Interface",
   "id": "904bb20a017e4d3a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T08:10:31.452771Z",
     "start_time": "2025-07-10T08:10:31.446756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from translate.clients.gpt import OpenAiApiClient, LanguageModel\n",
    "\n",
    "def translate(hirigana: str, model: str):\n",
    "    response = _select_model(hirigana, language_model=model)\n",
    "    for stream_so_far in response:\n",
    "        yield stream_so_far\n",
    "\n",
    "def _select_model(\n",
    "        hirigana: str,\n",
    "        language_model: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Choose the desired language model and execute the translation.\n",
    "    \"\"\"\n",
    "    if LanguageModel.GPT.casefold() == language_model.casefold():\n",
    "        return execute_gpt(hirigana=hirigana)\n",
    "    elif LanguageModel.CLAUDE.casefold() == language_model.casefold():\n",
    "        raise NotImplementedError(\"todo\")\n",
    "    raise ValueError(f\"Invalid model: {model}\")\n",
    "\n",
    "def execute_gpt(hirigana: str):\n",
    "    # Open GPT connection with system prompt.\n",
    "    gpt_client = OpenAiApiClient(system_prompt=_SYSTEM_PROMPT)\n",
    "    # Set user prompt for input hirigana\n",
    "    gpt_client.set_user_prompt(user_prompt_for(hirigana))\n",
    "    # Execute streaming\n",
    "    response = gpt_client.chat_stream()\n",
    "    print(f'response: {response}')\n",
    "    return response\n",
    "\n",
    "def test_execute_gpt():\n",
    "    execute_gpt(hirigana=\"かんじ\")\n",
    "\n",
    "test_execute_gpt()"
   ],
   "id": "b64bb78af2400efe",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T08:06:19.871656Z",
     "start_time": "2025-07-10T08:06:19.544108Z"
    }
   },
   "cell_type": "markdown",
   "source": "## UI",
   "id": "68a024ebb1c913fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T08:04:56.556505Z",
     "start_time": "2025-07-10T08:04:56.551846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    # gr.Markdown('### Translate Hirigana (ひらがな) to Kanji（漢字）')\n",
    "    with gr.Row():\n",
    "        # Input text - Corrected variable name here\n",
    "        input_hirigana = gr.Textbox(label=\"hirigana word or phrase\", lines=10)\n",
    "        output_kanji = gr.Textbox(label=\"kanji word or phrase\", lines=10)\n",
    "    with gr.Row():\n",
    "        # Model selection\n",
    "        model = gr.Dropdown([\"GPT\", \"Claude\"], label=\"Select model\", value=\"GPT\")\n",
    "        # Translate Button\n",
    "        translate_btn = gr.Button(\"Translate\")\n",
    "    # Translation execute - Corrected input reference\n",
    "    translate_btn.click(translate, inputs=[input_hirigana, model], outputs=[output_kanji])\n",
    "\n",
    "# Launch UI.\n",
    "ui.launch(inbrowser=True)"
   ],
   "id": "787cca37714afe92",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "6f3e7aa91f857bd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T08:02:55.440624Z",
     "start_time": "2025-07-10T08:02:55.430102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def translate(hirigana: str, model: str):\n",
    "    response = _select_model(hirigana, language_model=model)\n",
    "    for stream_so_far in response:\n",
    "        yield stream_so_far\n",
    "\n",
    "def _select_model(\n",
    "        hirigana: str,\n",
    "        language_model: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Choose the desired language model and execute the translation.\n",
    "    \"\"\"\n",
    "    if LanguageModel.GPT.casefold() == language_model.casefold():\n",
    "        return execute_gpt(hirigana=hirigana)\n",
    "    elif LanguageModel.CLAUDE.casefold() == language_model.casefold():\n",
    "        raise NotImplementedError(\"todo\")\n",
    "    raise ValueError(f\"Invalid model: {model}\")\n"
   ],
   "id": "663f23e9ccdc95e5",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### UI\n",
   "id": "2433543069856e33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T08:07:44.565072Z",
     "start_time": "2025-07-10T08:07:44.558960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    # gr.Markdown('### Translate Hirigana (ひらがな) to Kanji（漢字）')\n",
    "    with gr.Row():\n",
    "        # Input text - Corrected variable name here\n",
    "        input_hirigana = gr.Textbox(label=\"hirigana word or phrase\", lines=10)\n",
    "        output_kanji = gr.Textbox(label=\"kanji word or phrase\", lines=10)\n",
    "    with gr.Row():\n",
    "        # Model selection\n",
    "        model = gr.Dropdown([\"GPT\", \"Claude\"], label=\"Select model\", value=\"GPT\")\n",
    "        # Translate Button\n",
    "        translate_btn = gr.Button(\"Translate\")\n",
    "    # Translation execute - Corrected input reference\n",
    "    translate_btn.click(translate, inputs=[input_hirigana, model], outputs=[output_kanji])\n",
    "\n",
    "# Launch UI.\n",
    "ui.launch(inbrowser=True)"
   ],
   "id": "62fc2ae75185361d",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T08:07:21.220874Z",
     "start_time": "2025-07-10T08:07:19.560004Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "### Deterministic Unit Tests\n",
    "Unit tests for deterministic logic.\n",
    "\n",
    "#### Prerequisites:\n",
    "- `pytest`"
   ],
   "id": "8e21e53969e701ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T07:21:00.284781Z",
     "start_time": "2025-07-10T07:20:57.607679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import unittest\n",
    "from unittest.mock import MagicMock, patch\n",
    "import io\n",
    "import sys\n",
    "\n",
    "# Assume these are defined elsewhere or mock them for the test\n",
    "# For a bare-bones test, we'll define simple versions.\n",
    "class RoleName:\n",
    "    SYSTEM = \"system\"\n",
    "    USER = \"user\"\n",
    "    ASSISTANT = \"assistant\"\n",
    "\n",
    "DEFAULT_OPENAI_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "# Placeholder for the OpenAI class.\n",
    "# In a real application, this would be 'from openai import OpenAI'.\n",
    "# We define it here so OpenAiApiClient can be defined without a NameError,\n",
    "# and then we can patch it correctly.\n",
    "class OpenAI:\n",
    "    \"\"\"A dummy OpenAI class to allow OpenAiApiClient definition.\"\"\"\n",
    "    def __init__(self):\n",
    "        pass # No actual initialization needed for the dummy\n",
    "\n",
    "# The class to be tested (provided by the user)\n",
    "class OpenAiApiClient:\n",
    "    def __init__(\n",
    "        self,\n",
    "        system_prompt: str,\n",
    "        # todo: model version should derive from application-level config.\n",
    "        model_version: str = DEFAULT_OPENAI_MODEL,\n",
    "        user_prompt: str | None = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Create an OpenAI API client.\n",
    "\n",
    "        :param system_prompt: The prompt to use for prompting for the system prompt.\n",
    "                              This can be set with a later setter method.\n",
    "        :param user_prompt: Optional user prompt to initialize with.\n",
    "        \"\"\"\n",
    "        # This is the line we want to mock.\n",
    "        # When the test runs, the 'OpenAI' class will be replaced by a MagicMock\n",
    "        # due to the @patch decorator in the test class.\n",
    "        self._client = OpenAI()\n",
    "        # Setup a basic message hash for the model.\n",
    "        self._message_hashes = [\n",
    "            {\"role\": RoleName.SYSTEM, \"content\": system_prompt},\n",
    "            {\"role\": RoleName.USER, \"content\": user_prompt},\n",
    "        ]\n",
    "        self._model_version = model_version\n",
    "\n",
    "# Bare-bones unit test class\n",
    "class TestOpenAiApiClient(unittest.TestCase):\n",
    "    \"\"\"\n",
    "    A bare-bones unit test class for the OpenAiApiClient.\n",
    "    This class uses unittest.mock.patch to mock the external OpenAI dependency,\n",
    "    allowing for isolated testing of the OpenAiApiClient's initialization logic.\n",
    "    \"\"\"\n",
    "\n",
    "    # The patch target is now 'OpenAI' in the current module (__main__ in Jupyter).\n",
    "    # This will replace the 'OpenAI' class defined above with a MagicMock.\n",
    "    @patch('__main__.OpenAI')\n",
    "    def setUp(self, MockOpenAI):\n",
    "        \"\"\"\n",
    "        Set up the test environment before each test method.\n",
    "        This method is called automatically by the unittest framework.\n",
    "        It initializes a mock for the OpenAI client and creates an instance\n",
    "        of OpenAiApiClient with predefined prompts.\n",
    "        \"\"\"\n",
    "        # MockOpenAI is the MagicMock replacing the actual OpenAI class.\n",
    "        # mock_openai_instance is the result of calling MockOpenAI(),\n",
    "        # which is what self._client will be assigned to in OpenAiApiClient's __init__.\n",
    "        self.mock_openai_instance = MockOpenAI.return_value\n",
    "\n",
    "        self.system_prompt = \"You are a helpful assistant.\"\n",
    "        self.user_prompt = \"Hello, world!\"\n",
    "        self.client = OpenAiApiClient(\n",
    "            system_prompt=self.system_prompt,\n",
    "            user_prompt=self.user_prompt\n",
    "        )\n",
    "        self.client._client.assert_called()\n",
    "\n",
    "    def test_initialization(self):\n",
    "        \"\"\"\n",
    "        Test that the OpenAiApiClient is initialized correctly.\n",
    "        This test verifies:\n",
    "        1. The internal _client attribute is an instance of the mocked OpenAI client.\n",
    "        2. The _message_hashes list is correctly populated with system and user prompts.\n",
    "        3. The _model_version is set to the default if not specified.\n",
    "        \"\"\"\n",
    "        # Assert that the _client attribute is the mocked OpenAI instance\n",
    "        # This confirms that self._client = OpenAI() inside the class\n",
    "        # indeed called the mocked OpenAI and got its return value.\n",
    "        self.assertEqual(self.client._client, self.mock_openai_instance)\n",
    "\n",
    "        # Assert that _message_hashes is correctly initialized\n",
    "        expected_message_hashes = [\n",
    "            {\"role\": RoleName.SYSTEM, \"content\": self.system_prompt},\n",
    "            {\"role\": RoleName.USER, \"content\": self.user_prompt},\n",
    "        ]\n",
    "        self.assertEqual(self.client._message_hashes, expected_message_hashes)\n",
    "\n",
    "        # Assert that _model_version is set to the default\n",
    "        self.assertEqual(self.client._model_version, DEFAULT_OPENAI_MODEL)\n",
    "\n",
    "    def test_initialization_no_user_prompt(self):\n",
    "        \"\"\"\n",
    "        Test initialization when no user prompt is provided.\n",
    "        Ensures that _message_hashes handles a None user_prompt correctly.\n",
    "        \"\"\"\n",
    "        # Create a new client instance without a user prompt\n",
    "        client_no_user = OpenAiApiClient(system_prompt=\"Another system prompt.\")\n",
    "\n",
    "        expected_message_hashes = [\n",
    "            {\"role\": RoleName.SYSTEM, \"content\": \"Another system prompt.\"},\n",
    "            {\"role\": RoleName.USER, \"content\": None}, # User prompt should be None\n",
    "        ]\n",
    "        self.assertEqual(client_no_user._message_hashes, expected_message_hashes)\n",
    "        self.assertEqual(client_no_user._model_version, DEFAULT_OPENAI_MODEL)\n",
    "\n",
    "    def test_initialization_custom_model_version(self):\n",
    "        \"\"\"\n",
    "        Test initialization with a custom model version.\n",
    "        Verifies that the provided model_version is correctly assigned.\n",
    "        \"\"\"\n",
    "        custom_model = \"gpt-4-turbo\"\n",
    "        client_custom_model = OpenAiApiClient(\n",
    "            system_prompt=\"System for custom model.\",\n",
    "            model_version=custom_model\n",
    "        )\n",
    "\n",
    "        self.assertEqual(client_custom_model._model_version, custom_model)\n",
    "        # Ensure other attributes are still correctly set\n",
    "        expected_message_hashes = [\n",
    "            {\"role\": RoleName.SYSTEM, \"content\": \"System for custom model.\"},\n",
    "            {\"role\": RoleName.USER, \"content\": None},\n",
    "        ]\n",
    "        self.assertEqual(client_custom_model._message_hashes, expected_message_hashes)\n",
    "\n",
    "    def test_update_message_hashes(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This block is modified to run tests in a Jupyter Notebook cell\n",
    "# It collects tests and runs them using TextTestRunner,\n",
    "# which prints results without trying to exit the interpreter.\n",
    "if __name__ == '__main__':\n",
    "    # Create a test suite from the TestOpenAiApiClient class\n",
    "    # suite = unittest.TestSuite()\n",
    "    unittest.main()\n",
    "    print(\"All Unit Tests Passed\")"
   ],
   "id": "200602e956a937f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytest\r\n",
      "  Downloading pytest-8.4.1-py3-none-any.whl.metadata (7.7 kB)\r\n",
      "Collecting iniconfig>=1 (from pytest)\r\n",
      "  Downloading iniconfig-2.1.0-py3-none-any.whl.metadata (2.7 kB)\r\n",
      "Requirement already satisfied: packaging>=20 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pytest) (24.2)\r\n",
      "Collecting pluggy<2,>=1.5 (from pytest)\r\n",
      "  Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\r\n",
      "Requirement already satisfied: pygments>=2.7.2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pytest) (2.19.2)\r\n",
      "Downloading pytest-8.4.1-py3-none-any.whl (365 kB)\r\n",
      "Downloading pluggy-1.6.0-py3-none-any.whl (20 kB)\r\n",
      "Downloading iniconfig-2.1.0-py3-none-any.whl (6.0 kB)\r\n",
      "Installing collected packages: pluggy, iniconfig, pytest\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3/3\u001B[0m [pytest]\r\n",
      "\u001B[1A\u001B[2KSuccessfully installed iniconfig-2.1.0 pluggy-1.6.0 pytest-8.4.1\r\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T07:27:08.048670Z",
     "start_time": "2025-07-10T07:27:05.815712Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "cde51cc59984288e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m============================= test session starts ==============================\u001B[0m\r\n",
      "platform darwin -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /opt/anaconda3/envs/llms/bin/python3.11\r\n",
      "cachedir: .pytest_cache\r\n",
      "rootdir: /Users/aponte/personal_workspace/llm_engineering/week4\r\n",
      "plugins: anyio-4.9.0, langsmith-0.4.4, dash-3.0.4\r\n",
      "collected 1 item                                                               \u001B[0m\r\n",
      "\r\n",
      "tests/test_openai_client.py::test_client \u001B[32mPASSED\u001B[0m\u001B[32m                          [100%]\u001B[0m\r\n",
      "\r\n",
      "\u001B[33m=============================== warnings summary ===============================\u001B[0m\r\n",
      "tests/test_openai_client.py::test_client\r\n",
      "  /opt/anaconda3/envs/llms/lib/python3.11/site-packages/_pytest/python.py:161: PytestReturnNotNoneWarning: Test functions should return None, but tests/test_openai_client.py::test_client returned <class 'bool'>.\r\n",
      "  Did you mean to use `assert` instead of `return`?\r\n",
      "  See https://docs.pytest.org/en/stable/how-to/assert.html#return-not-none for more information.\r\n",
      "    warnings.warn(\r\n",
      "\r\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\r\n",
      "\u001B[33m========================= \u001B[32m1 passed\u001B[0m, \u001B[33m\u001B[1m1 warning\u001B[0m\u001B[33m in 0.01s\u001B[0m\u001B[33m =========================\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
